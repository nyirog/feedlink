#!/usr/bin/env python
from argparse import ArgumentParser, FileType
from json import dump
from os.path import dirname, realpath
from sys import argv, stdin, stdout
from urllib2 import urlopen, URLError

from jsonschema import validate

from feedlink.classify import classify, get_feed_types, UnknownFeedError
from feedlink.linkreader import get_links

_feed_types = get_feed_types()
schema = {
    'type': 'object',
    'properies': {
        feed_type: {'type': 'array'} for feed_type in _feed_types
    },
    'required': _feed_types,
}

def get_options(args):
    """
    Parse command line arguments and provide a dictionary from them.

    Args:
        args: list of cli arguments

    Returns:
        Dictionary of the parsed arguments
    """
    parser = ArgumentParser(
        description='Group the feed links from html doc '
                    'under their feed type into json doc',
        )
    parser.add_argument('html', nargs='?', type=FileType('r'),
        default=stdin, help='name of the input html file')
    parser.add_argument('--json', nargs='?', type=FileType('w'),
        default=stdout, help='name of the output json file')
    parser.add_argument('--timeout', type=int, default=60,
        help='timeout for urlopen')

    options = parser.parse_args(args)
    return vars(options)

def main(html, json, timeout):
    """
    Read the link from *html* document and write the classified feed links
    into *json*.

    Args:
        html: file handle of the html document
        json: file handle of the json file
        timeout: timeout for urlopen
    """
    links = get_links(html)
    feeds = build(links, timeout)
    validate(feeds, schema)
    dump(feeds, json, indent=4, sort_keys=True)
    return 0

def build(links, timeout):
    """
    Group the *links* under their feed types.

    Args:
        links: list of url links
        timeout: timeout for urlopen

    Retunrs:
        {'atpm': [<atom feed link>,], 'rss': [<rss feed link>,]}
    """
    feeds = {feed_type: [] for feed_type in _feed_types}
    for link in links:
        try:
            fh = urlopen(link, timeout=timeout)
        except URLError, error:
            continue
        try:
            feed_type = classify(fh)
        except UnknownFeedError, error:
            pass
        else:
            feeds[feed_type].append(link)
    return feeds

if __name__ == '__main__':
    options = get_options(argv[1:])
    status = main(**options)
    exit(status)

