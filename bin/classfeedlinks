#!/usr/bin/env python
from argparse import ArgumentParser, FileType
from json import dump
from os.path import dirname, realpath
from sys import argv, stdin, stdout
from urllib2 import urlopen

from feedlink.classify import classify, get_feed_types, UnknownFeedError
from feedlink.linkreader import get_links


def get_options(args):
    """
    Parse command line arguments and provide a dictionary from them.

    Args:
        args: list of cli arguments

    Returns:
        Dictionary of the parsed arguments
    """
    parser = ArgumentParser(
        description='Group the feed links from html doc '
                    'under their feed type into json doc',
        )
    parser.add_argument('html', nargs='?', type=FileType('r'),
        default=stdin, help='name of the input html file')
    parser.add_argument('--json', nargs='?', type=FileType('w'),
        default=stdout, help='name of the output json file')

    options = parser.parse_args(args)
    return vars(options)

def main(html, json):
    """
    Read the link from *html* document and write the classified feed links
    into *json*.

    Args:
        html: file handle of the html document
        json: file handle of the json file
    """
    links = get_links(html)
    feeds = build(links)
    dump(feeds, json, indent=4, sort_keys=True)
    return 0

def build(links):
    """
    Group the *links* under their feed types.

    Args:
        links: list of url links

    Retunrs:
        {'atpm': [<atom feed link>,], 'rss': [<rss feed link>,]}
    """
    feeds = {feed_type: [] for feed_type in get_feed_types()}
    for link in links:
        try:
            feed_type = classify(link)
        except UnknownFeedError, error:
            pass
        else:
            feeds[feed_type].append(link)
    return feeds

if __name__ == '__main__':
    options = get_options(argv[1:])
    status = main(**options)
    exit(status)

