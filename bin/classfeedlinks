#!/usr/bin/env python
from argparse import ArgumentParser, FileType
from json import dump
from os.path import dirname, realpath
from sys import argv, stdin, stdout, stderr
from urllib2 import urlopen, URLError

from jsonschema import validate

from feedlink.classify import classify, get_feed_types, UnknownFeedError
from feedlink.linkreader import get_links

_feed_types = get_feed_types()
schema = {
    'type': 'object',
    'properies': {
        feed_type: {'type': 'array'} for feed_type in _feed_types
    },
    'required': _feed_types,
}

def get_options(args):
    """
    Parse command line arguments and provide a dictionary from them.

    Args:
        args: list of cli arguments

    Returns:
        Dictionary of the parsed arguments
    """
    parser = ArgumentParser(
        description='Group the feed links from html doc '
                    'under their feed type into json doc',
        )
    parser.add_argument('html', nargs='?', type=FileType('r'),
        default=stdin, help='name of the input html file')
    parser.add_argument('--json', nargs='?', type=FileType('w'),
        default=stdout, help='name of the output json file')
    parser.add_argument('--timeout', type=int, default=60,
        help='timeout for urlopen')

    options = parser.parse_args(args)
    return vars(options)

def main(html, json, timeout):
    """
    Read the link from *html* document and write the classified feed links
    into *json*.

    Args:
        html: file handle of the html document
        json: file handle of the json file
        timeout: timeout for urlopen
    """
    links = get_links(html)
    feeds = build(links, timeout)
    validate(feeds, schema)
    dump(feeds, json, indent=4, sort_keys=True)
    return 0

def build(links, timeout):
    """
    Group the *links* under their feed types.

    Args:
        links: list of url links
        timeout: timeout for urlopen

    Retunrs:
        {'atpm': [<atom feed link>,], 'rss': [<rss feed link>,]}
    """
    feeds = {feed_type: [] for feed_type in _feed_types}
    for link in links:
        print >> stderr, 'process %s' % link
        try:
            fh = urlopen(link, timeout=timeout)
        except URLError, error:
            print >> stderr, 'url error: %s' % error.reason
            continue
        try:
            feed_type = classify(fh)
        except UnknownFeedError, error:
            print >> stderr, 'link is not a valid feed'
            continue
        print >> stderr, 'link is a %s feed' % feed_type
        feeds[feed_type].append(link)
    return feeds

if __name__ == '__main__':
    options = get_options(argv[1:])
    status = main(**options)
    exit(status)

