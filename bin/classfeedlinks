#!/usr/bin/env python
from argparse import ArgumentParser, FileType
from sys import argv, stdin, stdout
from os.path import dirname, realpath
from urllib2 import urlopen
from json import dump

from feedlink.linkreader import get_links
from feedlink.classify import classify, get_feed_types, UnknownFeedError


def get_options(args):
    parser = ArgumentParser(
        description='get the feed links from html files')
    parser.add_argument('html', nargs='?', type=FileType('r'),
        default=stdin, help='name of the input html file')
    parser.add_argument('--json', nargs='?', type=FileType('w'),
        default=stdout, help='name of the output json file')

    options = parser.parse_args(args)
    return vars(options)

def main(html, json):
    body =  html.read()
    links = get_links(body)
    feeds = build(links)
    dump(feeds, json)
    return 0

def build(links):
    feeds = {feed_type: [] for feed_type in get_feed_types()}
    for link in links:
        try:
            feed_type = classify(link)
        except UnknownFeedError, error:
            pass
        else:
            feeds[feed_type].append(link)
    return feeds

if __name__ == '__main__':
    options = get_options(argv[1:])
    status = main(**options)
    exit(status)

